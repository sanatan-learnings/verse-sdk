# Puranic Context Architecture

## Overview

The puranic context system allows the SDK to generate structured Puranic reference boxes
for verse files, grounded in actual source texts (PDFs, TXT files) rather than relying
solely on GPT-4's free recall.

## Directory Structure

```
data/
  puranic-references.yml          # registry of indexed sources
  sources/
    valmiki-ramayana.pdf          # source of truth (Git LFS for PDFs)
    skanda-purana.txt             # or plain text / markdown
  puranic-index/
    valmiki-ramayana.yml          # generated by indexing, then human-owned
    skanda-purana.yml
  embeddings/
    valmiki-ramayana.json         # versioned in git
    skanda-purana.json
    hanuman-chalisa.json          # verse embeddings (also versioned, not gitignored)
```

## `data/puranic-references.yml`

Written by `verse-index-sources` on successful indexing. Never manually created.

```yaml
valmiki-ramayana:
  enabled: true
  name: Valmiki Ramayana
  format: pdf                     # pdf | txt | md

skanda-purana:
  enabled: true
  name: Skanda Purana
  format: txt

hanuman-chalisa-commentary:
  enabled: false                  # indexed but not active yet
  name: Hanuman Chalisa Commentary
  format: pdf
```

File paths are fully predictable from the key and format:
- Source: `data/sources/<key>.<format>`
- Index:  `data/puranic-index/<key>.yml`
- Embeddings: `data/embeddings/<key>.json`

## `data/puranic-index/valmiki-ramayana.yml`

Generated once by `verse-index-sources`, then treated as human-owned (can be
hand-edited to correct AI errors).

```yaml
episodes:
  - id: sun-swallowing-episode
    type: story                   # story | concept | character | etymology | practice | cross_reference
    keywords: [hanuman, surya, childhood, bala-kanda]
    source:
      book: Bala Kanda
      sarga: 16
    summary_en: "Hanuman as a child mistook the sun for a ripe fruit..."
    summary_hi: "बाल हनुमान ने सूर्य को पके फल समझकर..."

  - id: hanuman-birth-episode
    type: character
    keywords: [hanuman, birth, anjana, vayu]
    source:
      book: Bala Kanda
      sarga: 15
    summary_en: "..."
    summary_hi: "..."
```

## Git Strategy

**`.gitattributes`** — PDFs tracked via Git LFS:
```
data/sources/*.pdf filter=lfs diff=lfs merge=lfs -text
```

**Nothing gitignored under `data/`** — all three artifacts (source, index, embeddings)
are versioned. Rationale:
- Sources are immutable reference texts
- Index is expensive to regenerate and may be hand-curated
- Embeddings are expensive to regenerate (API calls)

## Embeddings Provider

Sources contain Sanskrit/Hindi content — standard OpenAI embeddings are
English-optimised and perform poorly on Indic languages.

**Required first: Issue #1 — Bedrock Cohere multilingual embeddings**
- Cohere `embed-multilingual-v3` supports 100+ languages including Sanskrit, Hindi,
  Tamil, Bengali, Marathi
- 1024 dimensions vs OpenAI's 1536 (33% smaller)
- IAM authentication (no API keys)
- Same model used for both verse embeddings and puranic index embeddings

Dependency order:
```
Issue #1: Bedrock Cohere embeddings   ← implement first
     ↓
verse-index-sources                   ← uses multilingual embeddings
     ↓
verse-puranic-context                 ← uses index + embeddings
```

## Commands

### `verse-index-sources`

Indexes a source text into structured YAML episodes and embeddings.

```bash
# Index a specific source
verse-index-sources --file data/sources/valmiki-ramayana.pdf

# Re-index (overwrite existing index + embeddings)
verse-index-sources --file data/sources/valmiki-ramayana.pdf --force
```

**Steps:**
1. Detect format from extension (pdf / txt / md)
2. Extract text (pdfplumber for PDF, direct read for txt/md)
3. Chunk text into sections
4. GPT-4 structures each chunk into YAML episodes
5. Embed each episode using Bedrock Cohere multilingual
6. Write `data/puranic-index/<key>.yml`
7. Write `data/embeddings/<key>.json`
8. Update `data/puranic-references.yml` on success

### `verse-puranic-context`

Generates `puranic_context` frontmatter entries for verse files.

```bash
# Single verse
verse-puranic-context --collection hanuman-chalisa --verse chaupai-15

# All verses missing context
verse-puranic-context --collection bajrang-baan --all

# Force regenerate existing entries
verse-puranic-context --collection sundar-kaand --all --regenerate
```

**Steps:**
1. Load all `enabled: true` sources from `data/puranic-references.yml`
2. If no sources indexed → prompt:
   ```
   ⚠ No sources indexed. Run verse-index-sources first.
   Continue with GPT-4 free recall (lower accuracy)? [y/N]
   ```
3. Embed the verse text using Bedrock Cohere
4. Similarity search against `data/embeddings/<key>.json` → top 5-10 episodes
5. Send verse content + retrieved episodes to GPT-4
6. GPT-4 generates `puranic_context` entries mapped to the YAML schema
7. Inject `puranic_context` block into verse frontmatter

**As a flag on `verse-generate`:**
```bash
verse-generate --collection sundar-kaand --next --puranic-context
```

## `puranic_context` YAML Schema (in verse frontmatter)

```yaml
puranic_context:
  - id: sun-swallowing-episode
    type: story
    priority: high
    title:
      en: "The Sun-Swallowing Episode"
      hi: "सूर्य निगलने का प्रसंग"
    icon: ☀️
    story_summary:
      en: "..."
      hi: "..."
    theological_significance:
      en: "..."
      hi: "..."
    practical_application:
      en: "..."
      hi: "..."
    source_texts:
      - text: Valmiki Ramayana
        section: Bala Kanda, Sarga 16
    related_verses: []
```

## See Also

- [verse-embeddings](commands/verse-embeddings.md) — verse semantic search embeddings
- [Issue #1](https://github.com/sanatan-learnings/sanatan-verse-sdk/issues/1) — Bedrock Cohere multilingual embeddings
- [Issue #14](https://github.com/sanatan-learnings/sanatan-verse-sdk/issues/14) — verse-puranic-context command
